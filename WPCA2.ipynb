{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fives 0\n",
      "fives 1\n",
      "fives 2\n",
      "fives 3\n",
      "fives 4\n",
      "fives 5\n",
      "fives 6\n",
      "fives 7\n",
      "sixes 0\n",
      "sixes 1\n",
      "sixes 2\n",
      "sixes 3\n",
      "sixes 4\n",
      "sixes 5\n",
      "sixes 6\n",
      "sixes 7\n",
      "sixes 8\n",
      "sevens 0\n",
      "sevens 1\n",
      "sevens 2\n",
      "sevens 3\n",
      "sevens 4\n",
      "sevens 5\n",
      "sevens 6\n",
      "sevens 7\n",
      "sevens 8\n",
      "eights 0\n",
      "eights 1\n",
      "eights 2\n",
      "eights 3\n",
      "eights 4\n",
      "eights 5\n",
      "eights 6\n",
      "eights 7\n",
      "eights 8\n",
      "eights 9\n",
      "nines 0\n",
      "nines 1\n",
      "nines 2\n",
      "nines 3\n",
      "nines 4\n",
      "nines 5\n",
      "nines 6\n",
      "nines 7\n",
      "people 0\n",
      "people 1\n",
      "people 2\n",
      "people 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e06b869e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d9fd0f358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d9fc583c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1da2046710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d9fd3ee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1d9fe391d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from natsort import natsorted\n",
    "import matplotlib.cm as cm\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import mnist\n",
    "cmap = cm.hot\n",
    "\n",
    "def get_img_files(folder):\n",
    "    files = list(filter(lambda file: any(ext in file.lower() for ext in ['png','jpg','bmp']), os.listdir(folder)))\n",
    "    files = natsorted(files)[::1]\n",
    "    images = list(map(lambda x: cv2.imread(folder+'/'+x, 0), files))\n",
    "    return np.array(images)\n",
    "\n",
    "def img_to_coord(img):\n",
    "    coord_mat = np.zeros((3, img.shape[0]*img.shape[1]))\n",
    "    count = 0\n",
    "    for x in range(img.shape[1]):\n",
    "        for y in range(img.shape[0]):\n",
    "            coord_mat[0, count] = x\n",
    "            coord_mat[1, count] = img.shape[0]-y\n",
    "            coord_mat[2, count] = img[y, x]\n",
    "            count += 1\n",
    "    return coord_mat\n",
    "\n",
    "def img_to_coord_tensor(img):\n",
    "    height, width = img.shape\n",
    "    img_transpose = torch.transpose(img, 0, 1).contiguous().view(1, width * height)\n",
    "\n",
    "    x_coord = torch.arange(0, width).view(width, 1)\n",
    "    x_coord = x_coord.expand(width, height).contiguous()\n",
    "    x_coord = x_coord.view(1, width * height)\n",
    "\n",
    "    y_coord = torch.arange(height, 0, -1)\n",
    "    y_coord = y_coord.expand(width, height).contiguous()\n",
    "    y_coord = y_coord.view(1, width * height)\n",
    "\n",
    "    new_coord_matrix = np.vstack([x_coord.numpy(), y_coord.numpy()])\n",
    "    img_tensor = np.vstack([new_coord_matrix, img_transpose.data.numpy()])\n",
    "\n",
    "    return img_tensor\n",
    "\n",
    "def plot_coord_mat(coord_mat, ax):\n",
    "    ax.scatter(coord_mat[0, :], coord_mat[1, :], c=coord_mat[2, :])\n",
    "\n",
    "def rotation_matrix(degrees):\n",
    "    theta = np.radians(degrees)\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.array(((c,-s, 0), (s, c, 0), (0, 0, 1)))\n",
    "    return R\n",
    "\n",
    "def weighted_pca_regression(x_vec, y_vec, weights):\n",
    "    \"\"\"\n",
    "    Given three real-valued vectors of same length, corresponding to the coordinates\n",
    "    and weight of a 2-dimensional dataset, this function outputs the angle in radians\n",
    "    of the line that aligns with the (weighted) average and main linear component of\n",
    "    the data. For that, first a weighted mean and covariance matrix are computed.\n",
    "    Then u,e,v=svd(cov) is performed, and u * f(x)=0 is solved.\n",
    "    \"\"\"\n",
    "    input_mat = np.stack([x_vec, y_vec])\n",
    "    weights_sum = weights.sum()\n",
    "    # Subtract (weighted) mean and compute (weighted) covariance matrix:\n",
    "    mean_x, mean_y =  weights.dot(x_vec)/weights_sum, weights.dot(y_vec)/weights_sum\n",
    "    centered_x, centered_y = x_vec-mean_x, y_vec-mean_y\n",
    "    matrix_centered = np.stack([centered_x, centered_y])\n",
    "    weighted_cov = matrix_centered.dot(np.diag(weights).dot(matrix_centered.T)) / weights_sum\n",
    "    # We know that v rotates the data's main component onto the y=0 axis, and\n",
    "    # that u rotates it back. Solving u.dot([x,0])=[x*u[0,0], x*u[1,0]] gives\n",
    "    # f(x)=(u[1,0]/u[0,0])x as the reconstructed function.\n",
    "    u,e,v = np.linalg.svd(weighted_cov)\n",
    "    eig_val = np.sqrt(e)\n",
    "    if u[1,0] < 0:\n",
    "        eig_val[0] = -1*eig_val[0]\n",
    "    if u[0,1] < 0:\n",
    "        eig_val[1] = -1*eig_val[1]\n",
    "        \n",
    "    return eig_val[0]*u[:,0], eig_val[1]*u[:,1], np.array([mean_x, mean_y])\n",
    "        \n",
    "def coord_to_img(coord_mat, bbox=[-60,60,-60,60]):\n",
    "    x_min = bbox[0]\n",
    "    x_max = bbox[1]\n",
    "    y_min = bbox[2]\n",
    "    y_max = bbox[3]\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    \n",
    "    img = np.zeros([y_max-y_min, x_max-x_min])\n",
    "    for col in range(coord_mat.shape[1]):\n",
    "        x = coord_mat[0, col]\n",
    "        y = coord_mat[1, col]\n",
    "        val = coord_mat[2, col]\n",
    "        new_x = int(x - x_min)\n",
    "        new_y = int(y_max - y)\n",
    "        if (0 <= new_x) and (new_x < width) and (0 <= new_y) and (new_y < height):\n",
    "            img[new_y, new_x] = val\n",
    "    return img\n",
    "\n",
    "def object_extraction(coord_mat, min_val=0.2):\n",
    "    min_pixel_val = np.repeat([[min_val]], coord_mat.shape[1], axis=1) \n",
    "    extracted_object_coords = np.greater(coord_mat, min_pixel_val)\n",
    "    new_object = coord_mat.copy()[:,extracted_object_coords[2,:]]\n",
    "    coord_mat[2,extracted_object_coords[2,:]] = 0\n",
    "    return new_object\n",
    "\n",
    "def orientation_normalization(coord_mat):\n",
    "        weights = coord_mat[2, :]\n",
    "        primary_vector, seconday_vector, mean_vector = weighted_pca_regression(coord_mat[0,:], coord_mat[1,:], coord_mat[2,:])\n",
    "        angle = np.arctan2(primary_vector[1], primary_vector[0]) * 180 / np.pi\n",
    "        R = rotation_matrix(90-angle)\n",
    "        mean_mat = np.array([mean_vector[0], mean_vector[1], 0])\n",
    "        mean_mat = np.diag(mean_mat)\n",
    "        mean_mat = np.matmul(mean_mat, np.ones(coord_mat.shape))\n",
    "        eig_1 = np.linalg.norm(primary_vector)\n",
    "        eig_2 = np.linalg.norm(seconday_vector)\n",
    "        norm_scale_mat = np.zeros([3,3])\n",
    "        norm_scale_mat[0,0] = 9/eig_2\n",
    "        norm_scale_mat[1,1] = 18/eig_1\n",
    "        norm_scale_mat[2,2] = 1\n",
    "        transformed_mat = np.matmul(norm_scale_mat, np.matmul(R, coord_mat - mean_mat))\n",
    "        return transformed_mat, R, mean_mat\n",
    "    \n",
    "def object_extraction(coord_mat, min_val=0.2):\n",
    "    min_pixel_val = np.repeat([[min_val]], coord_mat.shape[1], axis=1) \n",
    "    extracted_object_coords = np.greater(coord_mat, min_pixel_val)\n",
    "    new_object = coord_mat.copy()[:,extracted_object_coords[2,:]]\n",
    "    coord_mat[2,extracted_object_coords[2,:]] = 0\n",
    "    return new_object\n",
    "\n",
    "def orientation_normalization(coord_mat):\n",
    "        weights = coord_mat[2, :]\n",
    "        primary_vector, seconday_vector, mean_vector = weighted_pca_regression(coord_mat[0,:], coord_mat[1,:], coord_mat[2,:])\n",
    "        angle = np.arctan2(primary_vector[1], primary_vector[0]) * 180 / np.pi\n",
    "        R = rotation_matrix(90-angle)\n",
    "        mean_mat = np.array([mean_vector[0], mean_vector[1], 0])\n",
    "        mean_mat = np.diag(mean_mat)\n",
    "        mean_mat = np.matmul(mean_mat, np.ones(coord_mat.shape))\n",
    "        eig_1 = np.linalg.norm(primary_vector)\n",
    "        eig_2 = np.linalg.norm(seconday_vector)\n",
    "        norm_scale_mat = np.zeros([3,3])\n",
    "        norm_scale_mat[0,0] = 9/eig_2\n",
    "        norm_scale_mat[1,1] = 18/eig_1\n",
    "        norm_scale_mat[2,2] = 1\n",
    "        transformed_mat = np.matmul(norm_scale_mat, np.matmul(R, coord_mat - mean_mat))\n",
    "        return transformed_mat, R, mean_mat\n",
    "\n",
    "def erase_object(img, new_object):\n",
    "    for col_num in range(new_object.shape[1]):\n",
    "        col = new_object[:,col_num]\n",
    "        img[img.shape[0]-col[1], col[0]] = 0\n",
    "\n",
    "def insert_object(img, new_object_coords, location):\n",
    "    for col_num in range(new_object_coords.shape[1]):\n",
    "        col = new_object_coords[:, col_num]\n",
    "        x = np.clip(location[0] + col[0], 0, img.shape[1] - 1)\n",
    "        y = np.clip(-1*(location[1] + col[1] - 1)+img.shape[0], 0, img.shape[0] - 1)\n",
    "        spill_over_x = x % 1\n",
    "        spill_over_y = y % 1\n",
    "        ceil_x = int(np.ceil(x))\n",
    "        lower_x_weight = 1 - spill_over_x\n",
    "        heigher_x_weight = spill_over_x\n",
    "        \n",
    "        ceil_y = int(np.ceil(y))\n",
    "        lower_y_weight = 1 - spill_over_y\n",
    "        heigher_y_weight = spill_over_y   \n",
    "        \n",
    "        pixel_value = col[2]\n",
    "        max_pixel_val = 0.5\n",
    "        img[ceil_y, ceil_x] = img[ceil_y, ceil_x] + pixel_value*heigher_y_weight*heigher_x_weight\n",
    "        img[ceil_y, ceil_x - 1] = img[ceil_y, ceil_x - 1] + pixel_value*lower_x_weight*heigher_y_weight\n",
    "        img[ceil_y - 1, ceil_x] = img[ceil_y - 1, ceil_x] + pixel_value*lower_y_weight*heigher_x_weight\n",
    "        img[ceil_y - 1, ceil_x - 1] = img[ceil_y - 1, ceil_x - 1] + pixel_value*lower_y_weight*lower_x_weight\n",
    "        img[ceil_y, ceil_x] = min(float(img[ceil_y, ceil_x]), max_pixel_val)\n",
    "        img[ceil_y, ceil_x - 1] = min(float(img[ceil_y, ceil_x - 1]), max_pixel_val)\n",
    "        img[ceil_y - 1, ceil_x] = min(float(img[ceil_y - 1, ceil_x]), max_pixel_val)\n",
    "        img[ceil_y - 1, ceil_x - 1] = min(float(img[ceil_y - 1, ceil_x - 1]), max_pixel_val)\n",
    "#         img[ceil_y, ceil_x] = pixel_value\n",
    "    return img\n",
    "\n",
    "def scale_and_rotate(img):\n",
    "    new_new_coord_mat = img_to_coord_tensor(img)\n",
    "    test = img_to_coord(img)\n",
    "    new_object = object_extraction(new_new_coord_mat, min_val=0)\n",
    "    erase_object(img, new_object)\n",
    "    new_object2, _, _ = orientation_normalization(new_object)\n",
    "    img = insert_object(img, new_object2, [50, 50])\n",
    "    return img\n",
    "    \n",
    "\n",
    "\n",
    "for folder in ['fives','sixes','sevens','eights','nines','people'][:]:\n",
    "    imgs = get_img_files(os.getcwd()+'/'+folder)\n",
    "\n",
    "    coord_mats = []\n",
    "    transformed_mats = []\n",
    "    transformed_mats_2 = []\n",
    "#     fig, ax = plt.subplots(3, figsize=(10,10))\n",
    "    for index, img in enumerate(imgs[:]):\n",
    "        img = cv2.resize(img, (100,100))\n",
    "        img = img/img.max()\n",
    "        img2 = Variable(torch.from_numpy(img))\n",
    "        coord_mat = img_to_coord(img)\n",
    "        coord_mat_2 = img_to_coord_tensor(img2)\n",
    "#          plot_coord_mat(, ax[1])\n",
    "#         ax[0].set_xlim([0,100])\n",
    "#         ax[0].set_ylim([0,100])\n",
    "#         ax[1].set_xlim([-60,60])\n",
    "#         ax[1].set_ylim([-60,60])\n",
    "#         ax[1].set_title(\"{}, {}\".format(eig_1, eig_2))\n",
    "#         tansform_mat, R, mean_mat = orientation_normalization(coord_mat.copy())\n",
    "        coord_mats.append(coord_to_img(coord_mat.copy(), bbox=[0,100,0,100]))\n",
    "#         transformed_mats_2.append(coord_to_img(np.matmul(R, coord_mat - mean_mat).copy(), bbox=[-60,60,-60,60]))\n",
    "        \n",
    "        img2 = scale_and_rotate(img2)\n",
    "        print(folder, index)\n",
    "        transformed_mats.append(img2.data.numpy())\n",
    "        del img2\n",
    "\n",
    "    fig2, ax2 = plt.subplots(1,2,figsize=(15,15))\n",
    "    combined_orig = []\n",
    "    combined_transformed = []\n",
    "    # plot_coord_mat(coord_mats[0] + coord_mats[1], ax2[0])\n",
    "    combined_orig = sum(coord_mats)\n",
    "    combined_transformed = sum(transformed_mats)\n",
    "#     combined_transformed_2 = sum(transformed_mats_2)\n",
    "    ax2[0].imshow(combined_orig)\n",
    "    ax2[0].set_title(\"Overlay of Original\")\n",
    "#     ax2[1].imshow(combined_transformed_2)\n",
    "#     ax2[1].set_title(\"Overlay of Rotated\")\n",
    "    ax2[1].imshow(combined_transformed)\n",
    "    ax2[1].set_title(\"Overlay of Rotated & scaled\")\n",
    "#     fig2.savefig(\"Sevens_full.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from natsort import natsorted\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.hot\n",
    "\n",
    "def get_img_files(folder):\n",
    "    files = list(filter(lambda file: any(ext in file.lower() for ext in ['png','jpg','bmp']), os.listdir(folder)))\n",
    "    files = natsorted(files)[::1]\n",
    "    images = list(map(lambda x: cv2.imread(folder+'/'+x, 0), files))\n",
    "    return np.array(images)\n",
    "\n",
    "def img_to_coord(img):\n",
    "    coord_mat = np.ones((3, img.shape[0]*img.shape[1]))\n",
    "    count = 0\n",
    "    for x in range(img.shape[1]):\n",
    "        for y in range(img.shape[0]):\n",
    "            coord_mat[:, count] = np.array([x, img.shape[0]-y, img[y,x]])\n",
    "            count += 1\n",
    "    return coord_mat\n",
    "\n",
    "def plot_coord_mat(coord_mat, ax):\n",
    "    ax.scatter(coord_mat[0, :], coord_mat[1, :], c=coord_mat[2, :])\n",
    "\n",
    "def rotation_matrix(degrees):\n",
    "    theta = np.radians(degrees)\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.array(((c,-s, 0), (s, c, 0), (0, 0, 1)))\n",
    "    return R\n",
    "\n",
    "def weighted_pca_regression(x_vec, y_vec, weights):\n",
    "    \"\"\"\n",
    "    Given three real-valued vectors of same length, corresponding to the coordinates\n",
    "    and weight of a 2-dimensional dataset, this function outputs the angle in radians\n",
    "    of the line that aligns with the (weighted) average and main linear component of\n",
    "    the data. For that, first a weighted mean and covariance matrix are computed.\n",
    "    Then u,e,v=svd(cov) is performed, and u * f(x)=0 is solved.\n",
    "    \"\"\"\n",
    "    input_mat = np.stack([x_vec, y_vec])\n",
    "    weights_sum = weights.sum()\n",
    "    # Subtract (weighted) mean and compute (weighted) covariance matrix:\n",
    "    mean_x, mean_y =  weights.dot(x_vec)/weights_sum, weights.dot(y_vec)/weights_sum\n",
    "    centered_x, centered_y = x_vec-mean_x, y_vec-mean_y\n",
    "    matrix_centered = np.stack([centered_x, centered_y])\n",
    "    weighted_cov = matrix_centered.dot(np.diag(weights).dot(matrix_centered.T)) / weights_sum\n",
    "    # We know that v rotates the data's main component onto the y=0 axis, and\n",
    "    # that u rotates it back. Solving u.dot([x,0])=[x*u[0,0], x*u[1,0]] gives\n",
    "    # f(x)=(u[1,0]/u[0,0])x as the reconstructed function.\n",
    "    u,e,v = np.linalg.svd(weighted_cov)\n",
    "    eig_val = np.sqrt(e)\n",
    "    if u[1,0] < 0:\n",
    "        eig_val[0] = -1*eig_val[0]\n",
    "    if u[0,1] < 0:\n",
    "        eig_val[1] = -1*eig_val[1]\n",
    "        \n",
    "    return eig_val[0]*u[:,0], eig_val[1]*u[:,1], np.array([mean_x, mean_y])\n",
    "        \n",
    "def coord_to_img(coord_mat, bbox=[-60,60,-60,60]):\n",
    "    x_min = bbox[0]\n",
    "    x_max = bbox[1]\n",
    "    y_min = bbox[2]\n",
    "    y_max = bbox[3]\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    \n",
    "    img = np.zeros([y_max-y_min, x_max-x_min])\n",
    "    for col in range(coord_mat.shape[1]):\n",
    "        x = coord_mat[0, col]\n",
    "        y = coord_mat[1, col]\n",
    "        val = coord_mat[2, col]\n",
    "        new_x = int(x - x_min)\n",
    "        new_y = int(y_max - y)\n",
    "        if (0 <= new_x) and (new_x < width) and (0 <= new_y) and (new_y < height):\n",
    "            img[new_y, new_x] = val\n",
    "    return img\n",
    "    \n",
    "    \n",
    "imgs = get_img_files(os.getcwd()+'/images')\n",
    "\n",
    "coord_mats = []\n",
    "transformed_mats = []\n",
    "# fig, ax = plt.subplots(3, figsize=(10,10))\n",
    "for index, img in enumerate(imgs[:8]):\n",
    "    img = cv2.resize(img, (100,100))\n",
    "    img = img/img.max()\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(9,9))\n",
    "#     ax.imshow(img)\n",
    "    \n",
    "    coord_mat = img_to_coord(img)\n",
    "\n",
    "    weights = coord_mat[2, :]\n",
    "\n",
    "    primary_vector, seconday_vector, mean_vector = weighted_pca_regression(coord_mat[0,:], coord_mat[1,:], coord_mat[2,:])\n",
    "    angle = np.arctan2(primary_vector[1], primary_vector[0]) * 180 / np.pi\n",
    "    print(angle, 90-angle)\n",
    "    ax[0].arrow(*mean_vector, *(primary_vector), width=1, head_width=4, head_length=4)\n",
    "    ax[0].arrow(*mean_vector, *(seconday_vector), width=1, head_width=4, head_length=4)\n",
    "    R = rotation_matrix(90-angle)\n",
    "    scale_mat = np.zeros([3,3])\n",
    "    scale_mat[:2,0] = primary_vector/np.linalg.norm(primary_vector)\n",
    "    scale_mat[:2,1] = seconday_vector/np.linalg.norm(seconday_vector)\n",
    "    scale_mat[2,2] = 1\n",
    "    second_scale_mat = np.matmul(scale_mat, np.diag([1, 1, 1]))\n",
    "    mean_mat = np.array([mean_vector[0], mean_vector[1], 0])\n",
    "    mean_mat = np.diag(mean_mat)\n",
    "    mean_mat = np.matmul(mean_mat, np.ones(coord_mat.shape))\n",
    "    plot_coord_mat(coord_mat, ax[0])\n",
    "    transformed_mat = np.matmul(R, np.matmul(scale_mat.T,np.matmul(second_scale_mat,coord_mat - mean_mat)) )\n",
    "#     transformed_mat = np.matmul(scale_mat.T,np.matmul(second_scale_mat,coord_mat - mean_mat))\n",
    "#     transformed_mat = np.matmul(second_scale_mat,coord_mat - mean_mat)\n",
    "#     transformed_mat = np.matmul(R, coord_mat - mean_mat)\n",
    "#     transformed_mat = coord_mat - mean_mat\n",
    "    plot_coord_mat(transformed_mat, ax[1])\n",
    "    ax[0].set_xlim([0,100])\n",
    "    ax[0].set_ylim([0,100])\n",
    "    ax[1].set_xlim([-60,60])\n",
    "    ax[1].set_ylim([-60,60])\n",
    "    \n",
    "    coord_mats.append(coord_to_img(coord_mat.copy(), bbox=[0,100,0,100]))\n",
    "    transformed_mats.append(coord_to_img(transformed_mat.copy(), bbox=[-60,60,-60,60]))\n",
    "    \n",
    "fig, ax2 = plt.subplots(1,2,figsize=(15,15))\n",
    "combined_orig = []\n",
    "combined_transformed = []\n",
    "# plot_coord_mat(coord_mats[0] + coord_mats[1], ax2[0])\n",
    "combined_orig = sum(coord_mats)\n",
    "combined_transformed = sum(transformed_mats)\n",
    "ax2[0].imshow(combined_orig)\n",
    "ax2[1].imshow(combined_transformed)\n",
    "\n",
    "# transformed_mats[1][2,:] += transformed_mats[0][2,:]\n",
    "# plot_coord_mat(coord_mats[0] + coord_mats[1], ax2[0])\n",
    "# # plot_coord_mat(transformed_mats[0], ax2[1])\n",
    "# plot_coord_mat(transformed_mats[1], ax2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_row(X, row):\n",
    "    return (np.ceil(X[row])-1).astype(int)\n",
    "\n",
    "def ceil_row(X, row):\n",
    "    return (np.ceil(X[row])).astype(int)\n",
    "\n",
    "def interpolate(X, change_row):\n",
    "    weights = []\n",
    "    Y = np.zeros(X.shape)\n",
    "    for (row, operation) in zip(range(len(X)), change_row):\n",
    "        Y[row] = operation(X, row)\n",
    "        weights.append(1 - np.abs(Y[row] - X[row]))\n",
    "#         print(Y[row])\n",
    "#     print(weights[0].shape)\n",
    "#     print(weights[1].shape)\n",
    "#     print(weights)\n",
    "    Y[2] = X[2]*weights[0]*weights[1]\n",
    "    return Y\n",
    "\n",
    "class RotationScaleNormalization(torch.nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(RotationScaleNormalization, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def img_to_coord_tensor(self, img, img_num, tensor_index):\n",
    "        _, _, height, width = img.shape\n",
    "        flattened_img = torch.transpose(img[img_num, tensor_index], 0, 1).contiguous().view(1, width * height)\n",
    "        x_coord = torch.arange(0, width).view(width, 1)\n",
    "        x_coord = x_coord.expand(width, height).contiguous()\n",
    "        x_coord = x_coord.view(1, width * height)\n",
    "\n",
    "        y_coord = torch.arange(height, 0, -1)\n",
    "        y_coord = y_coord.expand(width, height).contiguous()\n",
    "        y_coord = y_coord.view(1, width * height)\n",
    "\n",
    "        new_coord_matrix = np.vstack([x_coord.numpy(), y_coord.numpy()])\n",
    "        img_tensor = np.vstack([new_coord_matrix, flattened_img.data.numpy()])\n",
    "\n",
    "        return img_tensor\n",
    "\n",
    "    def rotation_matrix(self, degrees):\n",
    "        theta = np.radians(degrees)\n",
    "        c, s = np.cos(theta), np.sin(theta)\n",
    "        R = np.array(((c,-s, 0), (s, c, 0), (0, 0, 1)))\n",
    "        return R\n",
    "\n",
    "    def weighted_pca_regression(self, x_vec, y_vec, weights):\n",
    "        \"\"\"\n",
    "        Given three real-valued vectors of same length, corresponding to the coordinates\n",
    "        and weight of a 2-dimensional dataset, this function outputs the angle in radians\n",
    "        of the line that aligns with the (weighted) average and main linear component of\n",
    "        the data. For that, first a weighted mean and covariance matrix are computed.\n",
    "        Then u,e,v=svd(cov) is performed, and u * f(x)=0 is solved.\n",
    "        \"\"\"\n",
    "        input_mat = np.stack([x_vec, y_vec])\n",
    "        weights_sum = weights.sum()\n",
    "        # Subtract (weighted) mean and compute (weighted) covariance matrix:\n",
    "        mean_x, mean_y =  weights.dot(x_vec)/weights_sum, weights.dot(y_vec)/weights_sum\n",
    "        centered_x, centered_y = x_vec-mean_x, y_vec-mean_y\n",
    "        matrix_centered = np.stack([centered_x, centered_y])\n",
    "        weighted_cov = matrix_centered.dot(np.diag(weights).dot(matrix_centered.T)) / weights_sum\n",
    "        # We know that v rotates the data's main component onto the y=0 axis, and\n",
    "        # that u rotates it back. Solving u.dot([x,0])=[x*u[0,0], x*u[1,0]] gives\n",
    "        # f(x)=(u[1,0]/u[0,0])x as the reconstructed function.\n",
    "        u,e,v = np.linalg.svd(weighted_cov)\n",
    "        eig_val = np.sqrt(e)\n",
    "        if u[1,0] < 0:\n",
    "            eig_val[0] = -1*eig_val[0]\n",
    "        if u[0,1] < 0:\n",
    "            eig_val[1] = -1*eig_val[1]\n",
    "\n",
    "        return eig_val[0]*u[:,0], eig_val[1]*u[:,1], np.array([mean_x, mean_y])\n",
    "\n",
    "    def orientation_normalization(self, coord_mat, eig_width, eig_height):\n",
    "        weights = coord_mat[2, :]\n",
    "        primary_vector, seconday_vector, mean_vector = self.weighted_pca_regression(coord_mat[0,:], coord_mat[1,:], coord_mat[2,:])\n",
    "        angle = np.arctan2(primary_vector[1], primary_vector[0]) * 180 / np.pi\n",
    "        R = rotation_matrix(90-angle)\n",
    "        mean_mat = np.array([mean_vector[0], mean_vector[1], 0])\n",
    "        mean_mat = np.diag(mean_mat)\n",
    "        mean_mat = np.matmul(mean_mat, np.ones(coord_mat.shape))\n",
    "        eig_1 = np.linalg.norm(primary_vector)\n",
    "        eig_2 = np.linalg.norm(seconday_vector)\n",
    "        norm_scale_mat = np.zeros([3,3])\n",
    "        norm_scale_mat[0,0] = 1\n",
    "        norm_scale_mat[1,1] = 1\n",
    "        norm_scale_mat[2,2] = 1\n",
    "        transformed_mat = np.matmul(norm_scale_mat, np.matmul(R, coord_mat - mean_mat))\n",
    "        return transformed_mat, (90-angle), mean_mat\n",
    "\n",
    "    def object_extraction(self, coord_mat, min_val=0.2):\n",
    "        min_pixel_val = np.repeat([[min_val]], coord_mat.shape[1], axis=1) \n",
    "        extracted_object_coords = np.greater(coord_mat, min_pixel_val)\n",
    "        new_object = coord_mat.copy()[:,extracted_object_coords[2,:]]\n",
    "        coord_mat[2,extracted_object_coords[2,:]] = 0\n",
    "        return new_object\n",
    "\n",
    "    def erase_object(self, img, img_num, tensor_index, new_object):\n",
    "        _, _, height, width = img.shape\n",
    "        if new_object.shape[1] == 0:\n",
    "            return None\n",
    "#         print(img_num)\n",
    "#         print(tensor_index)\n",
    "#         print(new_object.shape, len(new_object))\n",
    "\n",
    "        img[np.array([img_num]), np.array([tensor_index]), height - new_object[1, :], new_object[0, :]] = torch.FloatTensor(new_object.shape[1]).zero_()\n",
    "\n",
    "    def insert_object2(self, img, img_num, tensor_index, new_object_coords, location):\n",
    "        if new_object_coords.shape[1] == 0:\n",
    "            return img\n",
    "        _, _, height, width = img.shape\n",
    "        xs = np.clip(location[0] + new_object_coords[0, :], 0, width - 1)\n",
    "        ys = np.clip(height - (location[1] + new_object_coords[1, :] - 1), 0, height - 1)\n",
    "        img[np.array([img_num]), np.array([tensor_index]), ys, xs] = torch.from_numpy(new_object_coords[2, :]).float()\n",
    "        return img\n",
    "\n",
    "    def insert_object3(self, img, tensor_index, new_object_coords, location):\n",
    "        _, height, width = img.shape\n",
    "        new_object_coords[0] = np.clip(location[0] + new_object_coords[0], 0, width - 1)\n",
    "        new_object_coords[1] = np.clip(-1*(location[1] + new_object_coords[1] - 1)+ height, 0, height - 1)\n",
    "        floor_floor = interpolate(new_object_coords, [floor_row, floor_row])\n",
    "        floor_ceil = interpolate(new_object_coords, [floor_row, ceil_row]) \n",
    "        ceil_floor = interpolate(new_object_coords, [ceil_row, floor_row])\n",
    "        ceil_ceil = interpolate(new_object_coords, [ceil_row, ceil_row])\n",
    "        inserted_coords = [ceil_ceil, floor_ceil, ceil_floor, floor_floor]\n",
    "        \n",
    "        def insert_val(xyz):\n",
    "#             print(xyz)\n",
    "            img[tensor_index, int(xyz[1]), int(xyz[0])] = img[tensor_index, int(xyz[1]), int(xyz[0])] + xyz[2]\n",
    "            img[tensor_index, int(xyz[1]), int(xyz[0])] = min(float(img[tensor_index, int(xyz[1]), int(xyz[0])]), 1.0)\n",
    "            return xyz\n",
    "        \n",
    "        for new_object in inserted_coords:\n",
    "            np.apply_along_axis(insert_val, 2, new_object.T.reshape((1,) + new_object.shape[::-1] ))\n",
    "#             xs = new_object[0]\n",
    "#             ys = new_object[1]\n",
    "#             new_object\n",
    "#             img[np.array([tensor_index]), ys, xs] += torch.autograd.Variable(torch.from_numpy(new_object[2, :]).float())\n",
    "#             img[np.array([tensor_index]), ys, xs] = torch.clamp(img[np.array([tensor_index]), ys, xs], -10, 1.0)\n",
    "        return img\n",
    "    \n",
    "    def insert_object(self, img, tensor_index, new_object_coords, location):\n",
    "        _, height, width  = img.shape\n",
    "        for col_num in range(new_object_coords.shape[1]):\n",
    "            col = new_object_coords[:, col_num]\n",
    "            x = np.clip(location[0] + col[0], 0, width - 1)\n",
    "            y = np.clip(-1*(location[1] + col[1] - 1)+ height, 0, height - 1)\n",
    "            spill_over_x = x % 1\n",
    "            spill_over_y = y % 1\n",
    "            ceil_x = int(np.ceil(x))\n",
    "            lower_x_weight = 1 - spill_over_x\n",
    "            heigher_x_weight = spill_over_x\n",
    "\n",
    "            ceil_y = int(np.ceil(y))\n",
    "            lower_y_weight = 1 - spill_over_y\n",
    "            heigher_y_weight = spill_over_y   \n",
    "\n",
    "            pixel_value = col[2]\n",
    "            max_pixel_val = 1.0\n",
    "            img[tensor_index, ceil_y, ceil_x] = img[tensor_index, ceil_y, ceil_x] + pixel_value*heigher_y_weight*heigher_x_weight\n",
    "            img[tensor_index, ceil_y, ceil_x - 1] = img[tensor_index, ceil_y, ceil_x - 1] + pixel_value*lower_x_weight*heigher_y_weight\n",
    "            img[tensor_index, ceil_y - 1, ceil_x] = img[tensor_index, ceil_y - 1, ceil_x] + pixel_value*lower_y_weight*heigher_x_weight\n",
    "            img[tensor_index, ceil_y - 1, ceil_x - 1] = img[tensor_index, ceil_y - 1, ceil_x - 1] + pixel_value*lower_y_weight*lower_x_weight\n",
    "            img[tensor_index, ceil_y, ceil_x] = min(float(img[tensor_index, ceil_y, ceil_x]), max_pixel_val)\n",
    "            img[tensor_index, ceil_y, ceil_x - 1] = min(float(img[tensor_index, ceil_y, ceil_x - 1]), max_pixel_val)\n",
    "            img[tensor_index, ceil_y - 1, ceil_x] = min(float(img[tensor_index, ceil_y - 1, ceil_x]), max_pixel_val)\n",
    "            img[tensor_index, ceil_y - 1, ceil_x - 1] = min(float(img[tensor_index, ceil_y - 1, ceil_x - 1]), max_pixel_val)\n",
    "        return img\n",
    "    \n",
    "    def reorient_basis(self, tensor_img_batch):\n",
    "        img_num, channel_num, new_height, new_width = tensor_img_batch.shape\n",
    "        for img_index in range(img_num):\n",
    "            for tensor_index in range(channel_num):\n",
    "                img_coord_mat = self.img_to_coord_tensor(tensor_img_batch, img_index, tensor_index)\n",
    "                new_object = self.object_extraction(img_coord_mat, min_val=self.threshold)\n",
    "\n",
    "                self.erase_object(tensor_img_batch, img_index, tensor_index, new_object)\n",
    "                new_object2, transform_angle, _ = self.orientation_normalization(new_object, new_width/10, new_height/5)\n",
    "                self.insert_object2(tensor_img_batch, img_index, tensor_index, new_object2, [new_width/2, new_height/2])        \n",
    "    \n",
    "    def forward(self, tensor_img):\n",
    "        self.reorient_basis(tensor_img)\n",
    "#         torch.autograd.Variable(torch.Tensor([[int(transform_angle)]]))\n",
    "        return tensor_img\n",
    "\n",
    "net = RotationScaleNormalization(0)    # define the network\n",
    "\n",
    "c_eight = cv2.imread('colored_eight.png')\n",
    "# c_eight = np.reshape(c_eight, (1,) + c_eight.shape)\n",
    "c_eight_torch = torch.from_numpy(c_eight)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,10))\n",
    "# print(c_eight.shape, c_eight_torch.shape)\n",
    "ax[0].imshow(c_eight)\n",
    "\n",
    "\n",
    "img2 = c_eight[np.newaxis]\n",
    "print(img2.shape)\n",
    "print(\"Original img channel max\", np.max(img2[:, :, :, 2]))\n",
    "img2 = Variable(torch.from_numpy(  np.transpose(img2, (0, 3, 1, 2))  ).float())\n",
    "\n",
    "transformed_img2 = net(img2)\n",
    "print(img2.size())\n",
    "normed_img = img2.data.numpy()\n",
    "normed_img = np.transpose(normed_img, (0, 2, 3, 1))\n",
    "print(normed_img.shape)\n",
    "ax[1].imshow(normed_img[0, :, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "mat_contents = sio.loadmat('/mnt/c/Users/Rees/Downloads/training_and_validation_batches/training_and_validation_batches/1.mat')\n",
    "nums = mat_contents['affNISTdata']\n",
    "import matplotlib.pyplot as plt\n",
    "print(nums[0][0][5].shape)\n",
    "labels = nums[0][0][5].T\n",
    "imgs = np.transpose(nums[0][0][2].reshape((40,40, 60000)), (2,0,1))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 200\n",
    "plt.imshow(imgs[index])\n",
    "print(imgs[index].shape)\n",
    "print(labels[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib qt\n",
    "RotationScaleNormalization\n",
    "\n",
    "class smallCNN(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.conv(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "\n",
    "print(net)  # net architecture\n",
    "\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "\n",
    "for folder in ['fives','sixes','sevens','eights','nines','people'][:1]:\n",
    "#     imgs = get_img_files(os.getcwd()+'/'+folder)\n",
    "\n",
    "    coord_mats = []\n",
    "    transformed_mats = []\n",
    "    rotation_list = []\n",
    "    for index, img in enumerate(imgs[:1]):\n",
    "        print(folder, index)\n",
    "        img = cv2.resize(img, (100,100))\n",
    "        img = img/img.max()\n",
    "        \n",
    "        img2 = Variable(torch.from_numpy(np.reshape(img, (1, 1, 100, 100))).float())\n",
    "        \n",
    "        coord_mat = img_to_coord(img)\n",
    "        coord_mats.append(coord_to_img(coord_mat.copy(), bbox=[0,100,0,100]))\n",
    "        \n",
    "        transformed_img2 = net(img2)\n",
    "        transformed_mats.append(np.reshape(transformed_img2.data.numpy(), (100,100)))\n",
    "#         rotation_list.append(rotation)\n",
    "\n",
    "    fig2, ax2 = plt.subplots(1,2,figsize=(15,15))\n",
    "    combined_orig = []\n",
    "    combined_transformed = []\n",
    "    combined_orig = sum(coord_mats)\n",
    "    combined_transformed = sum(transformed_mats)\n",
    "\n",
    "    ax2[0].imshow(combined_orig)\n",
    "    ax2[0].set_title(\"Overlay of Original\")\n",
    "    ax2[1].imshow(combined_transformed)\n",
    "    ax2[1].set_title(\"Rotated & scaled\", )\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (40,40)\n",
    "\n",
    "train_images = imgs[:5000]\n",
    "train_labels = labels[:5000]\n",
    "\n",
    "test_images = imgs[5000:]\n",
    "test_labels = labels[5000:]\n",
    "\n",
    "# train_images = mnist.train_images()\n",
    "# train_labels = mnist.train_labels()\n",
    "\n",
    "# test_images = mnist.test_images()\n",
    "# test_labels = mnist.test_labels()\n",
    "\n",
    "torch_train_images = torch.from_numpy(train_images)\n",
    "torch_train_labels = torch.from_numpy(train_labels)\n",
    "\n",
    "torch_test_images = torch.from_numpy(test_images)\n",
    "torch_test_labels = torch.from_numpy(test_labels)\n",
    "print(torch_train_images.shape)\n",
    "print(torch_train_labels.shape)\n",
    "\n",
    "print(torch_test_images.shape)\n",
    "print(torch_test_labels.shape)\n",
    "train = torch.utils.data.TensorDataset(torch_train_images.view(-1, 1, img_shape[1],img_shape[0]), torch_train_labels.view(-1, 1))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=False)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(torch_test_images.view(-1, 1, img_shape[1],img_shape[0]), torch_test_labels.view(-1, 1))\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(int(img_shape[1]/4)*int(img_shape[0]/4)*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, img_shape[0], img_shape[1])\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "class rotationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rotationCNN, self).__init__()\n",
    "        self.rotation = RotationScaleNormalization(0.1)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(int(img_shape[1]/4)*int(img_shape[0]/4)*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         out = x.view(-1, 1, img_shape[0], img_shape[1])\n",
    "#         out = self.rotation(x) \n",
    "        out = self.layer1(x)\n",
    "        out = self.rotation(out) \n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "#         out = torch.cat(out, )\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_limit = 1\n",
    "total_num = 64\n",
    "fig, ax = plt.subplots(64,2, figsize=(10,150))\n",
    "count = 0\n",
    "\n",
    "# cnn = CNN()\n",
    "# cnn2 = rotationCNN()\n",
    "# learning_rate = 0.001\n",
    "# # Loss and Optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# criterion2 = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "# optimizer2 = torch.optim.Adam(cnn2.parameters(), lr=learning_rate)\n",
    "net2 = RotationScaleNormalization(0.05)\n",
    "\n",
    "specific_batch = np.random.randint(50)\n",
    "\n",
    "print(\"LABEL\", \"CNN\", \"ROTATION\")\n",
    "for index, batch in enumerate(test_loader):\n",
    "    if index != num_limit:\n",
    "        continue\n",
    "    for index2, (img, label) in enumerate(zip(batch[0],batch[1])):\n",
    "        if index2 >= total_num:\n",
    "            break\n",
    "        img2 = img.clone()\n",
    "        img = img.view(1, 1,img_shape[1],img_shape[0])\n",
    "        test_img = Variable(img.float()/img.max())\n",
    "        test_img2 = Variable(img2.view(1, 1,img_shape[1],img_shape[0]).float()/img2.max())\n",
    "\n",
    "        outputs2 = cnn2(test_img)\n",
    "        _, prediction2 = torch.max(outputs2.data, 1)\n",
    "    \n",
    "        outputs = cnn(test_img)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        \n",
    "        digit_num = int(prediction[0])\n",
    "        digit_num2 = int(prediction2[0])\n",
    "\n",
    "        print(int(label), digit_num, digit_num2)\n",
    "#         if int(label) == 6:\n",
    "        ax[count, 0].set_title(digit_num2)\n",
    "        ax[count, 0].axis('off')\n",
    "        ax[count, 1].axis('off')\n",
    "        ax[count, 0].imshow(np.reshape(img2, (img_shape[1],img_shape[0])))\n",
    "        rotation = 1\n",
    "        rotated_img  = net2(test_img2)\n",
    "        ax[count, 1].imshow(np.reshape(rotated_img.data.numpy(), (img_shape[1],img_shape[0])))\n",
    "        ax[count, 1].set_title(int(rotation))\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "        \n",
    "#     new_img = new_img.numpy()\n",
    "#     new_img = new_img/new_img.max()\n",
    "#     torch_img = Variable(torch.from_numpy(new_img))\n",
    "#     ax[count, 0].set_title(new_label)\n",
    "#     ax[count, 0].imshow(new_img)\n",
    "#     ax[count, 1].imshow(net2(torch_img).data.numpy())\n",
    "#     count += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# # CNN Model (2 conv layer)\n",
    "# # img_shape = (40,40)\n",
    "# print()\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNN, self).__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.fc = nn.Linear(int(img_shape[1]/4)*int(img_shape[0]/4)*32, 10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 1, img_shape[0], img_shape[1])\n",
    "#         out = self.layer1(x)\n",
    "#         out = self.layer2(out)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc(out)\n",
    "#         return out\n",
    "        \n",
    "# class rotationCNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(rotationCNN, self).__init__()\n",
    "#         self.rotation = RotationScaleNormalization(0.1)\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "#             nn.BatchNorm2d(32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2))\n",
    "#         self.fc = nn.Linear(int(img_shape[1]/4)*int(img_shape[0]/4)*32, 10)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         out = x.view(-1, 1, img_shape[0], img_shape[1])\n",
    "#         out, rotation = self.rotation(x) \n",
    "#         out = self.layer1(out)\n",
    "#         out = self.layer2(out)\n",
    "#         print(out.shape)\n",
    "        \n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.fc(out)\n",
    "# #         out = torch.cat(out, )\n",
    "#         return out\n",
    "\n",
    "def train_net(model, data_loader, loss_function, optimizer_function, num_epochs=10, num_examples = 10):\n",
    "    # Train the Model\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            if i >= num_examples:\n",
    "                print(\"Batch Num\", i*epoch)\n",
    "                break\n",
    "            input_data = Variable(batch[0].float()/batch[0].max())\n",
    "            temp_labels = Variable(batch[1].long().squeeze(1))\n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer_function.zero_grad()\n",
    "            outputs = model(input_data)\n",
    "#             print(outputs.float())\n",
    "#             print(temp_labels.float())\n",
    "#             print(input_data.shape)\n",
    "            loss = loss_function(outputs, temp_labels)\n",
    "            loss.backward()\n",
    "            optimizer_function.step()\n",
    "\n",
    "cnn = CNN()\n",
    "cnn2 = rotationCNN()\n",
    "learning_rate = 0.001\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "optimizer2 = torch.optim.Adam(cnn2.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_net(cnn, train_loader, criterion, optimizer)\n",
    "train_net(cnn2, train_loader, criterion2, optimizer2, 10, 10)\n",
    "print(\"DONE!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "cnn2.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "correct2 = 0\n",
    "total2 = 0\n",
    "\n",
    "num_imgs = 500\n",
    "count = 0\n",
    "for testing_images, testing_labels in train_loader:\n",
    "    for image, label in zip(testing_images, testing_labels):\n",
    "        if count >= num_imgs:\n",
    "            break\n",
    "        count += 1\n",
    "        t_label = label.long()\n",
    "        t_image = Variable(image.view(1, 1, img_shape[1], img_shape[0]).float())\n",
    "        t_image2 = t_image.clone()\n",
    "        t_label2 = t_label.clone()\n",
    "\n",
    "        outputs2 = cnn2(t_image2)\n",
    "        _, predicted2 = torch.max(outputs2.data, 1)\n",
    "        total2 += t_label2.size(0)\n",
    "        correct2 += (predicted2 == t_label2).sum()\n",
    "        \n",
    "        outputs = cnn(t_image)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += t_label.size(0)\n",
    "        correct += (predicted == t_label).sum()\n",
    "\n",
    "print('Test Accuracy of the CNN on the {} images {}'.format(num_imgs, 100 * correct / num_imgs))\n",
    "print('Test Accuracy of the RotationCNN on the {} images {}'.format(num_imgs, 100 * correct2 / num_imgs))\n",
    "\n",
    "\n",
    "# Save the Trained Model\n",
    "# torch.save(cnn.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = Variable(torch.Tensor(coord_mats[0]), requires_grad=False)\n",
    "img_tensor.shape\n",
    "\n",
    "height, width = img_tensor.shape\n",
    "img_tensor = img_tensor.view(1, width * height)\n",
    "\n",
    "x_coord = Variable(torch.arange(0, width)).view(1, width)\n",
    "\n",
    "x_coord = x_coord.expand(height, width).contiguous()\n",
    "x_coord = x_coord.view(1, width * height)\n",
    "x_coord = x_coord - 50\n",
    "\n",
    "y_coord = Variable(torch.arange(height - 1,-1,-1).view(height,1))\n",
    "y_coord = y_coord.expand(width, height).contiguous()\n",
    "y_coord = y_coord.view(1,width * height)\n",
    "y_coord = y_coord - 50\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "coord_mat = torch.cat((x_coord, y_coord))\n",
    "img_tensor = torch.cat((coord_mat, img_tensor))\n",
    "R = rotation_matrix(45)\n",
    "img_tensor = img_tensor.data.numpy()\n",
    "plot_coord_mat(img_tensor, ax[0])\n",
    "# print(np.round_(img_tensor))\n",
    "print()\n",
    "img_tensor23 = np.matmul(R, img_tensor)\n",
    "plot_coord_mat(img_tensor23, ax[1])\n",
    "\n",
    "def coord_mat_to_img(coord_mat, width, height):\n",
    "    coord_mat = np.round_(coord_mat)\n",
    "    ind = np.lexsort((coord_mat[0,:],-1*coord_mat[1,:]))\n",
    "    coord_mat = coord_mat[:,ind]\n",
    "    pixels = coord_mat[2,:width*height]\n",
    "    pixels = np.reshape(pixels, (height, width))\n",
    "    return pixels\n",
    "\n",
    "fig2, ax2 = plt.subplots(1,2)\n",
    "ax2[0].imshow(coord_mat_to_img(img_tensor, 100, 100))\n",
    "ax2[1].imshow(coord_mat_to_img(img_tensor23, 100, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_extraction(coord_mat, min_val=0.2):\n",
    "    min_pixel_val = np.repeat([[min_val]], coord_mat.shape[1], axis=1) \n",
    "    extracted_object_coords = np.greater(coord_mat, min_pixel_val)\n",
    "    new_object = coord_mat.copy()[:,extracted_object_coords[2,:]]\n",
    "    coord_mat[2,extracted_object_coords[2,:]] = 0\n",
    "    return new_object\n",
    "\n",
    "def orientation_normalization(coord_mat):\n",
    "        weights = coord_mat[2, :]\n",
    "        primary_vector, seconday_vector, mean_vector = weighted_pca_regression(coord_mat[0,:], coord_mat[1,:], coord_mat[2,:])\n",
    "        angle = np.arctan2(primary_vector[1], primary_vector[0]) * 180 / np.pi\n",
    "        R = rotation_matrix(90-angle)\n",
    "        mean_mat = np.array([mean_vector[0], mean_vector[1], 0])\n",
    "        mean_mat = np.diag(mean_mat)\n",
    "        mean_mat = np.matmul(mean_mat, np.ones(coord_mat.shape))\n",
    "        eig_1 = np.linalg.norm(primary_vector)\n",
    "        eig_2 = np.linalg.norm(seconday_vector)\n",
    "        norm_scale_mat = np.zeros([3,3])\n",
    "        norm_scale_mat[0,0] = 9/eig_2\n",
    "        norm_scale_mat[1,1] = 18/eig_1\n",
    "        norm_scale_mat[2,2] = 1\n",
    "        transformed_mat = np.matmul(norm_scale_mat, np.matmul(R, coord_mat - mean_mat))\n",
    "        return transformed_mat\n",
    "\n",
    "def insert_object(img, new_object_coords, location):\n",
    "    for col_num in range(new_object_coords.shape[1]):\n",
    "        col = new_object_coords[:, col_num]\n",
    "        x = np.clip(location[0] + col[0], 0, img.shape[1] - 1)\n",
    "        y = np.clip(-1*(location[1] + col[1] - 1)+img.shape[0], 0, img.shape[0] - 1)\n",
    "        spill_over_x = x % 1\n",
    "        spill_over_y = y % 1\n",
    "        ceil_x = int(np.ceil(x))\n",
    "        lower_x_weight = 1 - spill_over_x\n",
    "        heigher_x_weight = spill_over_x\n",
    "        \n",
    "        ceil_y = int(np.ceil(y))\n",
    "        lower_y_weight = 1 - spill_over_y\n",
    "        heigher_y_weight = spill_over_y   \n",
    "        \n",
    "        pixel_value = col[2]\n",
    "        max_pixel_val = 0.5\n",
    "        img[ceil_y, ceil_x] += pixel_value*heigher_y_weight*heigher_x_weight\n",
    "        img[ceil_y, ceil_x - 1] += pixel_value*lower_x_weight*heigher_y_weight\n",
    "        img[ceil_y - 1, ceil_x] += pixel_value*lower_y_weight*heigher_x_weight\n",
    "        img[ceil_y - 1, ceil_x - 1] += pixel_value*lower_y_weight*lower_x_weight\n",
    "        img[ceil_y, ceil_x] = min(img[ceil_y, ceil_x], max_pixel_val)\n",
    "        img[ceil_y, ceil_x - 1] = min(img[ceil_y, ceil_x - 1], max_pixel_val)\n",
    "        img[ceil_y - 1, ceil_x] = min(img[ceil_y - 1, ceil_x], max_pixel_val)\n",
    "        img[ceil_y - 1, ceil_x - 1] = min(img[ceil_y - 1, ceil_x - 1], max_pixel_val)\n",
    "#         img[ceil_y, ceil_x] = pixel_value\n",
    "    return img\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(30,10))\n",
    "copy_tensor = img_tensor.copy()\n",
    "img_tensor2 = img_tensor.copy()\n",
    "# np.round_(img_tensor2[img_tensor2[1:] > 25])\n",
    "plot_coord_mat(copy_tensor, ax[1])\n",
    "\n",
    " \n",
    "\n",
    "# bigger = np.logical_and(bigger[0,:],bigger[1,:])\n",
    "\n",
    "# less = np.less(img_tensor2, max_box)\n",
    "# # less = np.logical_and(less[0,:],less[1,:])\n",
    "# img_tensor2 = img_tensor2[:,less[2,:]]\n",
    "new_object = object_extraction(img_tensor2, min_val=0.05)\n",
    "plot_coord_mat(new_object, ax[0])\n",
    "# plot_coord_mat(img_tensor2, ax[2])\n",
    "new_object2 = orientation_normalization(new_object.copy())\n",
    "plot_coord_mat(new_object2, ax[3])\n",
    "new_img = coord_mat_to_img(img_tensor2, 64, 64)\n",
    "new_img = np.zeros(new_img.shape)\n",
    "new_img = insert_object(new_img, new_object2, [29,35])\n",
    "\n",
    "ax[2].imshow(new_img[:,:])\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "X = torch.ByteTensor([data.tolist(), (data+5).tolist()])\n",
    "Y = torch.ByteTensor(data.tolist())\n",
    "print(X, X.shape)\n",
    "x = np.array([0, 2, 1])\n",
    "y = np.array([2, 2, 0])\n",
    "print(Y[2-y, x])\n",
    "X[[0], 2-y,x]\n",
    "# y = x[0, :, :]\n",
    "# z = y[[0,2]]\n",
    "# q = z[[0,2]]\n",
    "# print(q)\n",
    "# q = torch.ByteTensor(np.array([[1,1],[1,1]]))\n",
    "# print(q)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.1,2.2, 1],[3.5,4.5, 1],[5.7,6.7, 1],[7.8,8.8, 1],[9.9, 10.1, 1]]).T\n",
    "print(A)\n",
    "print(A.shape)\n",
    "# X[0, :] = np.floor(X[0, :])\n",
    "# pixel_value*heigher_y_weight*heigher_x_weight\n",
    "# pixel_value*lower_x_weight*heigher_y_weight\n",
    "# pixel_value*lower_y_weight*heigher_x_weight\n",
    "# pixel_value*lower_y_weight*lower_x_weight\n",
    "# ceil_x = int(np.ceil(x))\n",
    "# lower_x_weight = 1 - spill_over_x\n",
    "# heigher_x_weight = spill_over_x\n",
    "\n",
    "# ceil_y = int(np.ceil(y))\n",
    "# lower_y_weight = 1 - spill_over_y\n",
    "# heigher_y_weight = spill_over_y   \n",
    "def floor_row(X, row):\n",
    "    return (np.ceil(X[row])-1).astype(np.uint)\n",
    "\n",
    "def ceil_row(X, row):\n",
    "    return (np.ceil(X[row])).astype(np.uint)\n",
    "\n",
    "def interpolate(X, change_row):\n",
    "    weights = []\n",
    "    Y = np.zeros(A.shape)\n",
    "    for (row, operation) in zip(range(len(X)), change_row):\n",
    "        Y[row] = operation(X, row)\n",
    "        weights.append(1 - np.abs(Y[row] - X[row]))\n",
    "#     print(weights)\n",
    "    Y[2] = X[2]*weights[0]*weights[1]\n",
    "    return Y\n",
    "            \n",
    "            \n",
    "print('original\\n', A, A.shape)\n",
    "print('f_f\\n', interpolate(A, [floor_row, floor_row]), interpolate(A, [floor_row, floor_row]).shape)\n",
    "print('f_c\\n', interpolate(A, [floor_row, ceil_row]))\n",
    "print('c_f\\n', interpolate(A, [ceil_row, floor_row]))\n",
    "print('c_c\\n', interpolate(A, [ceil_row, ceil_row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[1.1,2.2, 1],[1.2,2.3, 1],[5.7,6.7, 1],[7.8,8.8, 1],[9.9, 10.1, 1]]).T\n",
    "R_IMG = np.zeros((11,11))\n",
    "R_IMG2 = R_IMG.copy()\n",
    "R_f_f = interpolate(R, [floor_row, floor_row])\n",
    "def F(X):\n",
    "#     print(X[1], X[0], X[2])\n",
    "    R_IMG[int(X[1]), int(X[0])] += X[2]\n",
    "    return X\n",
    "print(R)\n",
    "print(R_f_f)\n",
    "print(R_f_f[1])\n",
    "print(R_f_f[0])\n",
    "print()\n",
    "rfft = R_f_f.T.reshape((1,5,3))\n",
    "%time np.apply_along_axis(F, 2, rfft)\n",
    "%time R_IMG[R_f_f[1].astype(int), R_f_f[0].astype(int)] = R_IMG[R_f_f[1].astype(int), R_f_f[0].astype(int)] + R_f_f[2]\n",
    "print(R_IMG.max())\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "# R_IMG2[]\n",
    "ax[0].imshow(R_IMG)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = [1,2,3]\n",
    "map(lambda x: a = x, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
